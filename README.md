# Industrialisation d'un Pipeline NLP de Classification de Tickets Support (MLOps)

**Auteur :** Karima Chami
**Date :** 14 FÃ©vrier 2026
**Contexte :** Projet de certification RNCP DÃ©veloppeur.se en IA

---

## ğŸ“‹ Description du Projet

Ce projet vise Ã  automatiser la classification des tickets de support IT reÃ§us par email. L'objectif est de remplacer une catÃ©gorisation manuelle coÃ»teuse et hÃ©tÃ©rogÃ¨ne par un pipeline NLP batch robuste, industrialisÃ© selon les principes **MLOps**.

Le projet couvre l'ensemble du cycle de vie : du traitement des donnÃ©es textuelles Ã  l'entraÃ®nement du modÃ¨le, en passant par le stockage vectoriel, le monitoring de la dÃ©rive des donnÃ©es et l'orchestration sur Kubernetes.

### ğŸ¯ Objectifs
1.  **Automatiser** la classification des tickets.
2.  **AmÃ©liorer** le routage et la priorisation des tickets.
3.  **Garantir** la stabilitÃ© du modÃ¨le face Ã  l'Ã©volution des usages (Monitoring).

---

## ğŸ› ï¸ Architecture Technique & Pipeline

Le projet est entiÃ¨rement containerisÃ©.

### ğŸ—ï¸ Stack Technique
* **NLP & ModÃ©lisation :** Python, Hugging Face Transformers, scikit-learn.
* **Base de DonnÃ©es Vectorielle :** ChromaDB.
* **Monitoring ML :** Evidently AI.
* **Infrastructure & Orchestration :** Docker, Kubernetes (Minikube).
* **Monitoring Infra :** Prometheus, Grafana, cAdvisor, Node Exporter.
* **CI/CD :** GitHub Actions.

### ğŸ”„ Ã‰tapes du Pipeline (Batch)
1.  **Ingestion & PrÃ©traitement :** Nettoyage des textes (sujet + corps du mail), tokenisation, suppression des stopwords.
2.  **Embedding :** GÃ©nÃ©ration de reprÃ©sentations sÃ©mantiques via Hugging Face et stockage dans ChromaDB.
3.  **Classification :** EntraÃ®nement et infÃ©rence d'un modÃ¨le de classification supervisÃ©e.
4.  **Monitoring :** Analyse de la dÃ©rive des donnÃ©es (Data Drift) et des prÃ©dictions via Evidently AI.

---

## ğŸ“‚ Structure du RÃ©pertoire

```text
â”œâ”€â”€ data/                 # DonnÃ©es brutes et traitÃ©es
â”œâ”€â”€ models/               # ModÃ¨les entraÃ®nÃ©s (scikit-learn)
â”œâ”€â”€ notebooks/            # Analyse exploratoire (EDA)
â”œâ”€â”€ src/                  # Scripts sources (preprocessing, training, inference)
â”œâ”€â”€ monitoring/           # Configuration Prometheus/Grafana & Rapports Evidently
â”œâ”€â”€ k8s/                  # Manifestes Kubernetes (Jobs, CronJobs)
â”œâ”€â”€ Dockerfile            # Dockerfile du pipeline
â”œâ”€â”€ docker-compose.yml    # Orchestration du monitoring
â”œâ”€â”€ .github/workflows/    # CI/CD GitHub Actions
â””â”€â”€ README.md




